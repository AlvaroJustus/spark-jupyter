version: '3'
services:
  spark-master:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/spark-measure_2.13-0.24.jar
      - HADOOP_USER_NAME=spark
    ports:
      - "8080:8080"
      - "7077:7077"
      - "6066:6066"
    volumes:
      - ./work:/work
    networks:
      - spark-network

  spark-worker-1:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=5G
      - SPARK_WORKER_CORES=4
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/spark-measure_2.13-0.24.jar
      - HADOOP_USER_NAME=spark
    depends_on:
      - spark-master
    volumes:
      - ./work:/work
    networks:
      - spark-network

  spark-worker-2:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=5G
      - SPARK_WORKER_CORES=4
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/spark-measure_2.13-0.24.jar
      - HADOOP_USER_NAME=spark
    depends_on:
      - spark-master
    volumes:
      - ./work:/work
    networks:
      - spark-network

  jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.0
    environment:
      - PYSPARK_PYTHON=/opt/bitnami/python/bin/python
      - PYSPARK_DRIVER_PYTHON=jupyter
      - PYSPARK_DRIVER_PYTHON_OPTS="notebook --ip='*' --port=8888 --no-browser --allow-root"
      - SPARK_HOME=/usr/local/spark
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_USER=spark
      - SPARK_EXTRA_CLASSPATH=/opt/bitnami/spark/jars/spark-measure_2.13-0.24.jar
      - HADOOP_USER_NAME=spark
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./logs:/home/jovyan/work/logs
    networks:
      - spark-network
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
    command: >
      bash -c "
      mkdir -p /home/jovyan/jars &&
      wget -O /home/jovyan/jars/spark-measure_2.12-0.24.jar https://repo1.maven.org/maven2/ch/cern/sparkmeasure/spark-measure_2.12/0.24/spark-measure_2.12-0.24.jar &&
      pip install --no-cache-dir findspark sparkmeasure &&
      start-notebook.sh
      "

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=1
    ports:
      - "9870:9870"
      - "8020:8020"
    volumes:
      - namenode:/hadoop/dfs/name
      - ./hadoop-config/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    networks:
      - spark-network

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    environment:
      - CLUSTER_NAME=hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=1
      - HDFS_CONF_dfs_permissions_enabled=false
    volumes:
      - datanode:/hadoop/dfs/data
    networks:
      - spark-network
    depends_on:
      - namenode

networks:
  spark-network:
    driver: bridge

volumes:
  spark-worker-data:
  namenode:
  datanode: